\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}

\title{Assignment 10 - The last one!}
\author{Alex Boxall (u7468248) }
\date{May 2022}

\begin{document}

\maketitle

\section*{Collaboration Statement}
No collaboration.

\section*{Question 1}
\subsection*{a}
...

\subsection*{b}
...

\pagebreak

\section*{Question 2}
\subsection*{a}
We have:
$$f(x) = 5 + \int^{x^2}_1e^{t^2}dt$$
Now we will find the Taylor polynomial of degree 2 at $x = 1$ for $f$. Let $G$ be an antiderivative of $e^{t^2}$. Start by finding $f'(x)$:
\begin{align}
    f'(x) &= \frac{d}{dx}\left(5 + \int^{x^2}_1e^{t^2}dt\right) \notag \\
    &= \frac{d}{dx}\left(\int^{x^2}_1e^{t^2}dt\right) \notag \\
    &= G(x^2) - G(1) \notag \\
    &= 2x \cdot G'(x^2) - 0 \notag \\
    &= 2x \cdot e^{x^4} \notag
\end{align}
Now we find $f''(x)$:
\begin{align}
    f''(x) &= \frac{d}{dx}\left( 2x \cdot e^{x^4} \right) \notag \\
    &= 2e^{x^4} + 2x\cdot 4x^3\cdot e^{x^4} \notag \\
    &= 2e^{x^4} + 8x^4\cdot e^{x^4} \notag
\end{align}
Therefore, we have:
\begin{align}
    f(1) &= 5+\int^{1}_1e^{t^2}dt \notag \\
    &= 5 \notag \\
    f'(1) &= 2(1) \cdot e^{1^4} \notag \\
    &= 2e \notag \\
    f''(1) &= 2e^{1^4} + 8(1)^4\cdot e^{1^4}  \notag \\
    &= 2e + 8e \notag \\
    &= 10e \notag
\end{align}
The Taylor polynomial of degree 2 at $x = 1$ for $f$ is given by:
\begin{align}
    P(x) &= \frac{f(1)}{0!}\cdot(x - 1)^0 + \frac{f'(1)}{1!}\cdot(x - 1)^1 + \frac{f''(1)}{2!}\cdot(x - 1)^2 \notag \\
    &= f(1) + f'(1)\cdot(x - 1) + \frac{f''(1)}{2}\cdot(x - 1)^2 \notag 
\end{align}
By substituting the values above, we get:
\begin{align}
    P(x) &= 5 + 2e\cdot(x - 1) + \frac{10e}{2}\cdot(x - 1)^2 \notag \\
    &= 5 + 2ex - 2e + 5e(x^2 - 2x + 1) \notag \\
    &= 5 + 2ex - 2e + 5ex^2 - 10ex + 5e \notag \\
    &= (5 + 3e) - 8ex + 5ex^2 \notag
\end{align}

\subsection*{b}
We have $xf(x) = f''(x)$. Therefore the existence of $f(0)$ implies the existence of $f''(x)$... NO IDEA ABOUT $f^{(4)}$.\\
\\
We have:
\begin{align}
    f''(x) = xf(x) \notag
\end{align}
Thus, when $x = 0$, we have:
\begin{align}
    f''(0) &= 0 \cdot f(0) \notag \\
    &= 0 \cdot 0 \notag \\
    &= 0 \notag
\end{align}
Similarly, when $x = 0$, we have:
\begin{align}
    f'''(0) &= 0 \cdot f'(0) \notag \\
    &= 0 \cdot 1 \notag \\
    &= 0 \notag
\end{align}
And the same for $f^{(4)}$:
\begin{align}
    f^{(4)}(0) &= 0 \cdot f''(0) \notag \\
    &= 0 \cdot 0 \notag \\
    &= 0 \notag
\end{align}
Therefore, we get the rather boring Taylor polynomial of degree 4 about $x = 0$:
\begin{align}
    P(x) &= f(0) + \frac{f'(0)}{1!}\cdot(x - 0)^1 + \frac{f''(0)}{2!}\cdot(x - 0)^2 + \frac{f'''(0)}{3!}\cdot(x - 0)^3  + \frac{f^{(4)}(0)}{4!}\cdot(x - 0)^4 \notag \\
    &= f(0) + f'(0)\cdot x + \frac{f''(0)}{2}\cdot x^2 + \frac{f'''(0)}{6}\cdot x^3  + \frac{f^{(4)}(0)}{24}\cdot x^4 \notag \\
    &= 0 + 1 \cdot x + 0\cdot x^2 + 0\cdot x^3  + 0\cdot x^4 \notag \\
    &= x \notag
\end{align}
Surely not? QED
\pagebreak

\section*{Question 3}
\subsection*{a}
True. Linear transformations satisfy the following properties:
\begin{itemize}
    \item $T(cv) = cT(v)$ for any $v$, and scalar $c$.
    \item $T(v_1 + v_2) = T(v_1) + T(v_2)$ for any $v_1$ and $v_2$.
\end{itemize}
Let $T:M_{n\cross n} \to M_{n \cross n}$ be defined by $A \mapsto \frac{1}{2}(A - A^T)$. We have for any $a_{ij}$ in any $A \in M_{n\cross n}$, and scalar $c$:
\begin{align}
    T(cv) &= T(ca_{ij}) \notag \\
    &= \frac{1}{2}ca_{ij} - ca_{ji} \notag \\
    &= c(\frac{1}{2}a_{ij} - a_{ji}) \notag \\
    &= cT(a_{ij}) \notag
\end{align}
Hence the first property holds. Let $A, B \in M_{n\cross n}$. We have:
\begin{align}
    T(A+B) &= \frac{1}{2}(a_{ij} + b_{ij}) - (a_{ji} + b_{ji}) \notag \\
    &= \frac{1}{2}a_{ij} + \frac{1}{2}b_{ij} - a_{ji} - b_{ji} \notag \\
    &= \frac{1}{2}a_{ij} - a_{ji} + \frac{1}{2}b_{ij} - b_{ji} \notag \\
    &= T(a_{ij}) + T(b_{ij}) \notag
\end{align}
Hence the second property holds. As both properties hold, $T$ is a vector space. QED

\subsection*{b}
False. Proof by counterexample.\\
\\For $T$ to be a linear transformation, $cT(v) = T(cv)$ must be true for any $c \in \mathbb{R}$ and $v \in P_3$. Let $c = 2$, and $v = x^2$. Then we have:
\begin{align}
    T(cv) &= T((2x)^2) \notag \\
    &= T(4x^2) \notag \\
    &= (x^2 + x + 2)(4x^2) \notag \\
    &= 4(x^2 + x + 2)(x^2) \notag \\
    &= 4T(x^2) \notag
\end{align}
But $4 \not= k = 2$, so $T$ is not a linear transformation.
\pagebreak

\section*{Question 4}
Let $T: V \to W$ be a linear transformation between two vector spaces given by:
$$T(V) = \{w \in W\text{ : there exists } v\in V\text{ with } T(v)=w\}$$
For $T(V)$ to be a subspace of $W$, three properties must hold. These are:
\begin{itemize}
    \item 0 must be an element of $T(V)$
    \item $T(v_1) + T(v_2) = T(v_1 + v_2)$ must be true for any $v1, v_2 \in V$. Hence $T(v_1 + v_2)$ must also be in $W$.
    \item $T(cv) = cT(v)$ must be true for any $v \in V$, and scalar $c$, and hence both $T(cv)$ and $cT(v)$ must be in $W$.
\end{itemize}
If these properties hold, then the remaining properties of being a vector space are inherited from the fact that $V$ is a vector space.\\
\\From the definition of a linear transformation, we have that $T(0) = 0$. As $V$ is a vector space, $0$ is an element of $V$, and so $T(0)$ exists and is equal to $0$. Hence $0 \in T(V)$.\\
\\The remaining two properties (addition and scalar multiplication) also hold, as they directly follow from the fact that linear transformations satisfy these properties. Therefore $V(T)$ is a subspace of $W$. QED

\pagebreak

\section*{Question 5}
\subsection*{a}
The characteristic polynomial has no real roots (see part b), and therefore when graphed does not intercept the x axis.

\subsection*{b}
The characteristic polynomial of $A$ is given by $p(\lambda) = \det(\lambda I - A)$. Therefore we have:
\[
p(\lambda) = \begin{bmatrix}
\lambda && -1 \\ 
1 && \lambda
\end{bmatrix}\\
= \lambda^2 + 1 
\]
By setting $0 = \lambda^2 + 1$, we can find the eigenvalues as $\lambda_1$ and $\lambda_2$.
\begin{align}
    -1    &= \lambda^2 \notag \\
    \pm i &= \lambda \notag
\end{align}
Hence we have that $\lambda_1 = -i$, and $\lambda_2 = i$.

\subsection*{c}
To find the eigenvector when $\lambda_1 = -i$, we need to find the null space of $\lambda_1 I - A$. To do this, we first row reduce $\lambda_1 I - A$.
\[
\lambda_1 I - A = \begin{bmatrix}
-i && 1 \\ -1 && -i
\end{bmatrix} ~  \begin{bmatrix}
1 && i \\ 0 && 0
\end{bmatrix}
\]
To get the null space, we solve $x_1 + ix_2 = 0$. We find that the null space, and thus the first eigenvector is:
\[ v_1 = 
\begin{bmatrix}
-i \\ 1
\end{bmatrix}
\]
As $A$ is a real matrix, the second eigenvector $v_2$ is the complex conjugate. Hence:\[ v_2 =
\begin{bmatrix}
i \\ 1
\end{bmatrix}
\]

\subsection*{d}
To get $P$, we put $v_1$ and $v_2$ together as the column of a matrix:
\[ P = 
\begin{bmatrix}
-i && i \\ 1 && 1
\end{bmatrix}
\]
We find $D$ by putting the values of $\lambda$ on the diagonal, and leaving the rest as zero.
\[ D = 
\begin{bmatrix}
-i && 0 \\ 0 && i
\end{bmatrix}
\]
\end{document}
